\subsection{Optimizer}

One of the most essential parameters to configure is the optimizer, which updates the weights of our network. Each optimizer also has its own parameters that we need to tune as well. These parameters define the friction factor and the most common values range from 0.8 to 0.999. 

We train the baseline model on three optimizers with various parameters as depicted in the Table \ref{tab:optimizer1}. For each optimizer, we use the same learning rate of $1e^{-3}$. 

{\renewcommand{\arraystretch}{1.4}
\begin{table}[h]
\centering
\begin{tabular}{|l|l|cc|cc|}
\hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Optimizer}}} & \multirow{2}{*}{\textbf{Parameters}} & \multicolumn{2}{c|}{\textbf{Validation loss}} & \multicolumn{2}{c|}{\textbf{Validation accuracy (\%)}} \\ \cline{3-6} 
\multicolumn{1}{|c|}{} &  & \multicolumn{1}{c|}{real data} & \begin{tabular}[c]{@{}c@{}}synthetic \\ data\end{tabular} & \multicolumn{1}{c|}{real data} & \begin{tabular}[c]{@{}c@{}}synthetic \\ data\end{tabular} \\ \hline
\textit{SGD} & m = 0.8 & \multicolumn{1}{c|}{0.962530} & 0.122709 & \multicolumn{1}{c|}{52.00} & 88.27 \\ \hline
\textit{SGD} & m = 0.88 & \multicolumn{1}{c|}{2.437670} & 0.017428 & \multicolumn{1}{c|}{61.33} & 98.39 \\ \hline
\textit{SGD} & m = 0.9 & \multicolumn{1}{c|}{1.338834} & 0.143461 & \multicolumn{1}{c|}{49.66} & 75.60 \\ \hline
\textit{SGD} & m = 0.99 & \multicolumn{1}{c|}{2.711914} & 0.008364 & \multicolumn{1}{c|}{71.66} & 99.18 \\ \hline
\textit{RMSProp} & a = 0.8 & \multicolumn{1}{c|}{6.060928} & 0.025563 & \multicolumn{1}{c|}{68.00} & 98.73 \\ \hline
\textit{RMSProp} & a = 0.88 & \multicolumn{1}{c|}{4.561706} & 0.032053 & \multicolumn{1}{c|}{76.33} & 98.86 \\ \hline
\textit{RMSProp} & a = 0.9 & \multicolumn{1}{c|}{1.881074} & 0.019174 & \multicolumn{1}{c|}{73.33} & 98.74 \\ \hline
\textit{RMSProp} & a = 0.99 & \multicolumn{1}{c|}{2.197012} & 0.006177 & \multicolumn{1}{c|}{78.66} & 99.48 \\ \hline
\textit{ADAM} & b = 0.9, 0.999 & \multicolumn{1}{c|}{1.017293} & 0.006852 & \multicolumn{1}{c|}{79.33} & 99.31 \\ \hline
\textit{ADAM} & b = 0.8, 0.888 & \multicolumn{1}{c|}{5.399825} & 0.022405 & \multicolumn{1}{c|}{69.99} & 98.67 \\ \hline
\textit{ADAM} & b = 0.9, 0.888 & \multicolumn{1}{c|}{2.163878} & 0.016903 & \multicolumn{1}{c|}{75.66} & 98.82 \\ \hline
\textit{ADAM} & b = 0.8, 0.999 & \multicolumn{1}{c|}{2.172440} & 0.006850 & \multicolumn{1}{c|}{75.00} & 99.39 \\ \hline
\textit{ADAM} & b = 0.99, 0.999 & \multicolumn{1}{c|}{1.347257} & 0.006457 & \multicolumn{1}{c|}{76.66} & 99.47 \\ \hline
\textit{ADAM} & b = 0.999, 0.999 & \multicolumn{1}{c|}{2.500495} & 0.009130 & \multicolumn{1}{c|}{75.99} & 99.42 \\ \hline
\end{tabular}
\caption{Validation loss and accuracy on multiple models with different optimizers and various parameters.}
\label{tab:optimizer1}
\end{table}
}


Based on the results on the validation set we can see that the worst-performing was SGD with momentum. It's quite interesting that with the increasing validation loss of the real data, the accuracy was increasing as well. However, this doesn't apply to RMSProp or ADAM, as we can see that usually, the higher loss means lower accuracy. Of these two optimizers, the better performance is achieved with ADAM. 